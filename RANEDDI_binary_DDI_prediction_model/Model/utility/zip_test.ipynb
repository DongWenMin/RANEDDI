{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599101215493",
   "display_name": "Python 3.6.9 64-bit ('py36': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import scipy.spatial.distance as dist\n",
    "os.chdir(\"../../Data/1317_ddi_chem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_chem(chem):\n",
    "    degree = np.sum(chem,axis=0)\n",
    "    index_mapping = {}\n",
    "    i = 0\n",
    "    for index in range(len(degree)):\n",
    "        if not degree[index] == 0:\n",
    "            index_mapping[i] =index\n",
    "            i += 1\n",
    "\n",
    "    buffer = chem.T\n",
    "    new_chem = []\n",
    "    for index in range(buffer.shape[0]):\n",
    "        if index in index_mapping.values():\n",
    "            new_chem.append(buffer[index])\n",
    "    new_chem = np.array(new_chem).T\n",
    "    return new_chem,index_mapping\n",
    "\n",
    "def get_w_new_chem(new_chem,index_mapping):\n",
    "    degree = np.sum(new_chem,axis=0)\n",
    "    assert not min(degree) == 0\n",
    "    w_new_chem = []\n",
    "    for index in range(len(new_chem.T)):\n",
    "        w_new_chem.append(new_chem.T[index]/degree[index])\n",
    "    w_new_chem = np.array(w_new_chem).T\n",
    "    return w_new_chem\n",
    "\n",
    "def get_inter_f(binary,new_chem):\n",
    "    #利用tf-idf计算权重值\n",
    "    #idf：log10 inter_count/(fre+1)\n",
    "    #接着计算药物的反应药物集合中特定结构出现的 次数/总次数 值\n",
    "    total = 0\n",
    "    inter_count =0\n",
    "    inter_f = []\n",
    "    total_buffer = np.zeros((new_chem.shape[1]))\n",
    "    for i in range(len(binary)):\n",
    "        total = 0\n",
    "        buffer = np.zeros((new_chem.shape[1]))\n",
    "        for j in range(len(binary)):\n",
    "            if binary[i][j] == 1:\n",
    "                total = sum(new_chem[j])\n",
    "                buffer = buffer + new_chem[j]#获取反应药物的子结构特征数量和\n",
    "                inter_count += 1\n",
    "        tf = buffer/total\n",
    "        total_buffer = total_buffer + buffer\n",
    "        inter_f.append(tf)\n",
    "        if i% 200 == 0:\n",
    "            print(\"%d/%d\"%(i,len(binary)))\n",
    "    #idf\n",
    "    fre = total_buffer\n",
    "    idf = np.log10(inter_count/(fre+1))\n",
    "    inter_f = [i*idf for i in inter_f]\n",
    "    inter_f = np.array(inter_f)\n",
    "    inter_f_ravel = inter_f.ravel()\n",
    "    #减小数据偏差，大于10的数据值设置为10\n",
    "    for index in range(len(inter_f_ravel)):\n",
    "        if inter_f_ravel[index]>10:\n",
    "            inter_f_ravel[index] = 10.\n",
    "    inter_f = inter_f_ravel.reshape(inter_f.shape[0],inter_f.shape[1])\n",
    "    return inter_f  \n",
    "\n",
    "def chem_type(i):\n",
    "    if i>=0 and i<=114:\n",
    "        return str(0)\n",
    "    elif i>=115 and i<=262:\n",
    "        return str(1)\n",
    "    elif i>=263 and i<=326:\n",
    "        return str(2)\n",
    "    elif i>=327 and i<=415:\n",
    "        return str(3)\n",
    "    elif i>=416 and i<=459:\n",
    "        return str(4)\n",
    "    elif i>=460 and i<=712:\n",
    "        return str(5)\n",
    "    elif i>=713 and i<=880:\n",
    "        return str(6)\n",
    "    else:\n",
    "        print('exception')\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_1317 = np.load('1317_drug_v5.npz',allow_pickle=True)\n",
    "data_1317 = data_1317['data'].item()\n",
    "chem = data_1317[\"Drug_chem_structure\"]\n",
    "binary = data_1317[\"Adj_binary\"]\n",
    "new_chem,index_mapping = get_new_chem(chem)#new_chem去除了度为0的化学结构，index_mapping是683-》881的映射\n",
    "# w_new_chem = get_w_new_chem(new_chem,index_mapping)\n",
    "# inter_f  = get_inter_f(binary,new_chem)#药物相互作用药物的特征，权重\n",
    "w_f = data_1317['interaction_feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据的重新生成  kg_final.txt  权重保留0.05的边加入到网络当中\n",
    "# 药物 类别 属性\n",
    "with open(\"kg_final.txt\",'w') as f:\n",
    "    index = 0\n",
    "    for drug in w_f:\n",
    "        # 对当前的特征进行排序(前150个子结构)\n",
    "        sort_index = np.argsort(drug)[-1::-1][0:150]\n",
    "        for i in range(len(drug)):\n",
    "            if w_f[index][i] >= 0.05 and i in sort_index:\n",
    "                f.writelines(str(index) +' '+chem_type(index_mapping[i])+' '+str(i+1317)+'\\n')\n",
    "        index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[254 265 199 425 362 224 478 143 511 491]\n[0.6380728  0.59357701 0.56149264 0.53990657 0.49121346 0.485607\n 0.48031382 0.47882695 0.47089431 0.46180015]\n"
    }
   ],
   "source": [
    "a = w_f[0]\n",
    "index_sort1= np.argsort(a)[-1::-1]\n",
    "print(index_sort1[0:10])\n",
    "print(a[index_sort1][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[337 374 466 211 450 159 419 377 194 263]\n[1.00897034 0.98573759 0.96274278 0.90382602 0.90130397 0.85822297\n 0.83775707 0.8352062  0.8309763  0.81967037]\n"
    }
   ],
   "source": [
    "a = w_f[1]\n",
    "index_sort2= np.argsort(a)[-1::-1]\n",
    "print(index_sort2[0:10])\n",
    "print(a[index_sort2][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "41"
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "len(set(index_sort1[0:100]) & set(index_sort4[0:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[254 199 265  16 478 425 224 362 143 479]\n[0.84335441 0.79188331 0.78193693 0.76941087 0.7518707  0.74417666\n 0.72535119 0.71659802 0.71494359 0.6905088 ]\n"
    }
   ],
   "source": [
    "a = w_f[2]\n",
    "index_sort3= np.argsort(a)[-1::-1]\n",
    "print(index_sort3[0:10])\n",
    "print(a[index_sort3][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[ 12 123 178 120 206 461 369 194 215 221]\n[0.42970311 0.42549825 0.39880929 0.39849377 0.39787523 0.39631833\n 0.39543901 0.39211006 0.39193495 0.39082993]\n"
    }
   ],
   "source": [
    "a = w_f[777]\n",
    "index_sort4= np.argsort(a)[-1::-1]\n",
    "print(index_sort4[0:10])\n",
    "print(a[index_sort4][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "#稀疏矩阵的构建，其中包括药物之间的相互作用权重（1）和药物属性之间的权重\n",
    "#一个小demo\n",
    "# ddi_matrix = np.array([[0,1,0,1],[1,0,1,0],[0,1,0,1],[1,0,1,0]])\n",
    "# dfi_matrix = np.array([[0.3,0.5,0.1],[0.1,0.1,0.7],[0.6,0.4,0.4],[0.5,0.2,0.2]])\n",
    "def get_w_sp_matrix(ddi_matrix,dfi_matrix):\n",
    "    #药物个数，特征个数\n",
    "    n_drug = ddi_matrix.shape[0]\n",
    "    n_feature = dfi_matrix.shape[1]\n",
    "    #先转稀疏矩阵\n",
    "    ddi_sp = sp.coo_matrix(ddi_matrix)\n",
    "    dfi_sp = sp.coo_matrix(dfi_matrix)\n",
    "    #ddi的行列\n",
    "    ddi_row = ddi_sp.row\n",
    "    ddi_col = ddi_sp.col+n_drug\n",
    "    #dfi的行列\n",
    "    dfi_row = dfi_sp.row + n_drug\n",
    "    dfi_col = dfi_sp.col +2*n_drug\n",
    "    #最终的行列\n",
    "    rows =  np.concatenate((ddi_row,dfi_row))\n",
    "    cols =  np.concatenate((ddi_col,dfi_col))\n",
    "    values = np.concatenate((ddi_sp.data,dfi_sp.data))\n",
    "    #\n",
    "    result = sp.coo_matrix((values, (rows, cols)), shape=(n_drug*2 + n_feature, n_drug*2 + n_feature))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_w_sp_matrix(binary,inter_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "result.toarray()[0][1300:1400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = ['Drug_id',\n",
    " 'Num_of_type2',\n",
    " 'All_proteins',\n",
    " 'Adj_binary',\n",
    " 'Drug_chem_structure',\n",
    " 'Drug_protein',\n",
    " 'Sim_chem_by_jaccard',\n",
    " 'Adj_multi2',\n",
    " 'interaction_feature'\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = {\"Drug_id\":data_1317[\"Drug_id\"],'Num_of_type2':86,'All_proteins':data_1317[\"All_proteins\"],\n",
    "           'Adj_binary':data_1317[\"Adj_binary\"],'Adj_multi2':data_1317[\"Adj_multi2\"],\n",
    "           'Drug_chem_structure':data_1317[\"Drug_chem_structure\"],'interaction_feature':inter_f,\n",
    "           'Drug_protein':data_1317[\"Drug_protein\"],'Sim_chem_by_jaccard':data_1317[\"Sim_chem_by_jaccard\"],'index':index}\n",
    "np.savez('1317_drug_v5.npz',data = new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1317 = np.load('1317_drug_v4.npz',allow_pickle=True)\n",
    "data_1317 = data_1317['data'].item()\n",
    "chem = data_1317[\"Drug_chem_structure\"]\n",
    "binary = data_1317[\"Adj_binary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_adj():\n",
    "    adj = np.zeros((1317,1317))\n",
    "    with open('train.txt') as f:\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            line = list(map(int,line.split(' ')[:-1]))\n",
    "            drug1 = line[0]\n",
    "            drug2 = line[1:]\n",
    "            for d in drug2:\n",
    "                adj[drug1,d] = adj[d,drug1] = 1\n",
    "            line = f.readline()\n",
    "    return adj\n",
    "adj = get_train_adj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0\n20\n40\n60\n80\n100\n120\n140\n160\n180\n200\n220\n240\n260\n280\n300\n320\n340\n360\n380\n400\n420\n440\n460\n480\n500\n520\n540\n560\n580\n600\n620\n640\n660\n680\n700\n720\n740\n760\n780\n800\n820\n840\n860\n880\n900\n920\n940\n960\n980\n1000\n1020\n1040\n1060\n1080\n1100\n1120\n1140\n1160\n1180\n1200\n1220\n1240\n1260\n1280\n1300\n"
    }
   ],
   "source": [
    "def get_inter_sim(binary):\n",
    "    inter_sim = np.zeros((1317,1317))\n",
    "    for row in range(len(binary)):\n",
    "        for column in range(row,len(binary)):\n",
    "            matv = np.array([binary[row],binary[column]])\n",
    "            inter_sim[row,column] = inter_sim[column,row] = math.exp(-(dist.pdist(matv,'jaccard')))  \n",
    "        if row %20 == 0:\n",
    "            print(row)\n",
    "    return inter_sim\n",
    "binary = data_1317[\"Adj_binary\"]\n",
    "inter_sim = get_inter_sim(binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[1.        , 0.40063658, 0.46653651, ..., 0.3806186 , 0.39930378,\n        0.37288453],\n       [0.40063658, 1.        , 0.46891724, ..., 0.37132559, 0.38338499,\n        0.37056795],\n       [0.46653651, 0.46891724, 1.        , ..., 0.3862939 , 0.38145282,\n        0.37974551],\n       ...,\n       [0.3806186 , 0.37132559, 0.3862939 , ..., 1.        , 0.36787944,\n        0.37416783],\n       [0.39930378, 0.38338499, 0.38145282, ..., 0.36787944, 1.        ,\n        0.36787944],\n       [0.37288453, 0.37056795, 0.37974551, ..., 0.37416783, 0.36787944,\n        1.        ]])"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "inter_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#某一对负样本的可信度\n",
    "def get_reliable_negative(d1,d2):\n",
    "    sim1,sim2 = 0.,0.\n",
    "    #d2与d1的反应药物之间的相似度\n",
    "    for index in range(len(adj[d1])):\n",
    "        if adj[d1][index] == 1:\n",
    "            sim1 += inter_sim[d2][index]\n",
    "    for index in range(len(adj[d2])):\n",
    "        if adj[d2][index] == 1:\n",
    "            sim2 += inter_sim[d1][index]\n",
    "    return math.exp(-(sim1+sim2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\n110\n120\n130\n140\n150\n160\n170\n180\n190\n200\n210\n220\n230\n240\n250\n260\n270\n280\n290\n300\n310\n320\n330\n340\n350\n360\n370\n380\n390\n400\n410\n420\n430\n440\n450\n460\n470\n480\n490\n500\n510\n520\n530\n540\n550\n560\n570\n580\n590\n600\n610\n620\n630\n640\n650\n660\n670\n680\n690\n700\n710\n720\n730\n740\n750\n760\n770\n780\n790\n800\n810\n820\n830\n840\n850\n860\n870\n880\n890\n900\n910\n920\n930\n940\n950\n960\n970\n980\n990\n1000\n1010\n1020\n1030\n1040\n1050\n1060\n1070\n1080\n1090\n1100\n1110\n1120\n1130\n1140\n1150\n1160\n1170\n1180\n1190\n1200\n1210\n1220\n1230\n1240\n1250\n1260\n1270\n1280\n1290\n1300\n1310\n"
    }
   ],
   "source": [
    "reliable_negative = defaultdict(list)\n",
    "for row in range(1317):\n",
    "    for column in range(row,1317):\n",
    "        if adj[row,column] == 0:\n",
    "            neg_score = get_reliable_negative(row,column)\n",
    "            reliable_negative[row].append((column,neg_score))\n",
    "    if row %10 == 0:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reliable_negative_m = defaultdict(list)\n",
    "for k,value in reliable_negative.items():\n",
    "    for v in value:\n",
    "        reliable_negative_m[k].append((v[1],v[0]))\n",
    "        reliable_negative_m[v[0]].append((v[1],k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reliable_negative_dict = {}\n",
    "for k,value in reliable_negative_m.items():\n",
    "    reliable_neg = sorted(list(set(value)))\n",
    "    reliable_negative_dict[k] = reliable_neg[-1::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reliable_negative_dict[0][0:200]\n",
    "new_data = {\"reliable_negative_dict\":reliable_negative_dict}\n",
    "np.savez('reliable_negative_dict.npz',data = new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = np.load('reliable_negative_dict.npz',allow_pickle=True)\n",
    "negative = negative['data'].item()\n",
    "negative_dict = negative[\"reliable_negative_dict\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1092"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "len(negative_dict[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}